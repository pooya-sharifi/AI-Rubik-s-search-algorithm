{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pooya-sharifi/AI-Rubik-s-search-algorithm/blob/main/Copy_of_2024_Lab2_Ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S02d9PimAZKJ"
      },
      "source": [
        "# Lab 2 Exercises for COMP 691 (Deep Learning)\n",
        "\n",
        "In this lab we will learn some basics of Pytorch.\n",
        "- You will implement a feedforward neural network using different implementation styles.\n",
        "- Understand how to use torch autograd for calculating gradients.\n",
        "- Learn how to use GPUs for computation speed.\n",
        "\n",
        "Save your answers for this lab as they will be used for part of Lab 3.\n",
        "\n",
        "Start by making a **copy** of this notebook in your Google Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIDPxv5l2qpI"
      },
      "source": [
        "# Exercise 1: Loading the dataset\n",
        "\n",
        "Below we will create a dataloader for the MNIST training data using torchvision package (following e.g. https://github.com/pytorch/examples/blob/master/mnist/main.py#L112-L120).\n",
        "\n",
        "The dataloader iterates over the training set and will output **mini-batches of size 256** image samples.\n",
        "\n",
        "**Note**: you do not need to use the image labels in the rest of this lab since you will not be doing any training.\n",
        "\n",
        "Remarks about using GPU:\n",
        "\n",
        "- The \"device\" variable allows us to select which device to place the data on. Modify your colab (or local environment) to use a GPU.\n",
        "\n",
        "- To use GPU in Google Colab, go to Runtime then choose \"change runtime type\". Then choose the hardware accelerator as GPU.\n",
        "\n",
        "- In your Google Colab notebook set the variable device to \"cuda\", rerunning the cell below such that the data is placed on GPU inside the for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets,transforms\n",
        "import torch\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,\n",
        "                                           batch_size=256,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "device='cuda'\n",
        "\n",
        "for (data, target) in train_loader:\n",
        "  data = data.to(device)\n",
        "  target = target.to(device)\n",
        "print(data.shape)\n",
        "print(target.shape)"
      ],
      "metadata": {
        "id": "QfDg7vxJbGRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743c7876-1c2d-4e12-be82-1cf38ecb9f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 1, 28, 28])\n",
            "torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you ran the code cell above, you will notice that the data is a tensor of shape ([256, 1, 28, 28]) = (batch_size, number of color channels, length of image in pixels, width of image in pixels)"
      ],
      "metadata": {
        "id": "9dVarmxYuQMI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14MBuiusdZmA"
      },
      "source": [
        "# Exercise 2: Building a neural network from the ground up!\n",
        "\n",
        "Network Architecture:\n",
        "- Using only torch primitives (e.g. [torch.matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html), [torch._relu](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html), etc) implement a simple feedforward neural network with 2 hidden layers that takes as input MNIST digits (28x28) and outputs **a single scalar value** i.e., the class. Avoid using any functions from torch.nn class.\n",
        "\n",
        "\n",
        "- You may select the hidden layer width (greater than 20) and activations (tanh, relu, sigmoid, others) as desired.  \n",
        "\n",
        "- A typical layer will transform its inputs as follows: $y = σ (Wx+b) $, where $σ$ is the non-linear activation function.\n",
        "\n",
        "- Initialize the weights  with [uniform random values](https://pytorch.org/docs/stable/generated/torch.rand.html) in the range -1 to 1 and [biases at 0](https://pytorch.org/docs/stable/generated/torch.zeros.html).\n",
        "\n",
        "Data:\n",
        "\n",
        "Using the data obtained from Exercise 1, make a forward pass through the dataset in mini-batches of 256 (feed the network data). To check you are on the right track, the shape of your output should be ([256]).\n",
        "\n",
        "**Hint:** Remember that the goal is to feed the MNIST images and get a class label for each image. In this exercise there is no training so do not expect that the label will be meaningful/correct!\n",
        "\n",
        "Pay attention to the shape of the input and how it gets changed as it passes from one layer to the next in the forward pass. Ex: (256, 28*28) -> (256, hiddden_size_1) -> (256,hidden_size_2) -> (256,1). This will help you when constructing the layers of the network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhZ0I_q7dnb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613e13e2-34b9-45f2-aee1-e974eba04448"
      },
      "source": [
        "import torch\n",
        "\n",
        "## Initialize and track the parameters using a list or dictionary (modify the None)\n",
        "param_dict = {\n",
        "    \"W0\": torch.randn(128, 28*28, requires_grad= True).to(device),\n",
        "    \"b0\": torch.randn(128, requires_grad= True).to(device),\n",
        "    \"W1\": torch.randn(64, 128, requires_grad= True).to(device),\n",
        "    \"b1\": torch.randn(64, requires_grad= True).to(device),\n",
        "    \"W2\": torch.randn(1, 64, requires_grad= True).to(device),\n",
        "    \"b2\": torch.randn(1, requires_grad= True).to(device),\n",
        "    }\n",
        "\n",
        "\n",
        "## Make sure your parameters in param_dict require gradient for training the network later!\n",
        "\n",
        "\n",
        "\n",
        "## Define the network\n",
        "def my_nn(input, param_dict):\n",
        "    r\"\"\"Performs a single forward pass of a Neural Network with the given\n",
        "    parameters in param_dict.\n",
        "\n",
        "    Args:\n",
        "        input (torch.tensor): Batch of images of shape (B, H, W), where B is\n",
        "            the number of input samples,and H and W are the image height and\n",
        "            width respectively.\n",
        "        param_dict (dict of torch.tensor): Dictionary containing the parameters\n",
        "            of the neural network. Expects dictionary keys to be of format\n",
        "            \"W#\" and \"b#\" where # is the layer number.\n",
        "\n",
        "    Returns:\n",
        "        torch.tensor: Neural network output of shape (B, )\n",
        "    \"\"\"\n",
        "    #Reshape the input image from HxW to a flat vector\n",
        "    x = input.view(-1 , 28*28)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    layer_2 = torch.matmul( x, param_dict[\"W0\"].T) + param_dict[\"b0\"]\n",
        "    layer_2 = torch.relu(layer_2)\n",
        "\n",
        "    layer_3 = torch.matmul( layer_2, param_dict[\"W1\"].T) + param_dict[\"b1\"]\n",
        "    layer_3 = torch.relu(layer_3)\n",
        "\n",
        "    output = torch.matmul( layer_3, param_dict[\"W2\"].T) + param_dict[\"b2\"]\n",
        "    output = torch.relu(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "#   data = data.to(device)\n",
        "#   #forward pass\n",
        "out_put=my_nn(data,param_dict)\n",
        "print(out_put.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndXpk3C5bwQ8"
      },
      "source": [
        "#Exercise 3: Implementing the same network using torch.nn.module\n",
        "\n",
        "Implement a new torch.nn.module that performs the equivalent of the network in Exercise 2 and call it \"model\".\n",
        "\n",
        "Initialize it with the same weights (ex: **nn.Linear**(in_features,out_features) so that you could have a fair comparison between the two networks. The way to do this is through **weight.data** = insert your desired weights. You can do a similar thing with the bias).\n",
        "\n",
        "Validate the outputs of this network is the same as the one in Exercise 2 on MNIST training set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(28*28, 128)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(128, 64)\n",
        "        self.linear3 = nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1 , 28*28)\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "model = Model().to(device)\n",
        "\n",
        "for (data, target) in train_loader:\n",
        "    data = data.to(device)\n",
        "    output = model(data)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct-CkGJFBoYC",
        "outputId": "8b11373d-6daa-4715-eee2-0e8df7c5e69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3.1: Validating that the two implementations are equal.\n",
        "\n",
        "First you will need to make sure the param_dict from Exercise 2 and the nn module version have the same parameters (weights and biases).\n",
        "\n",
        "You can do this for example using: \"**model.linear1.weight.data** = copy.deepcopy(param_dict['W0'].data.T)\".\n",
        "\n",
        "**Note**: that we do a deepcopy just to make sure this model is separate from the one in the above cell"
      ],
      "metadata": {
        "id": "KLgkHOa6TnsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "#Copy parameters from param_dict to nn module parameters\n",
        "model.linear1.weight.data = copy.deepcopy(param_dict['W0'].data)\n",
        "model.linear1.bias.data = copy.deepcopy(param_dict['b0'].data)\n",
        "model.linear2.weight.data = copy.deepcopy(param_dict['W1'].data)\n",
        "model.linear2.bias.data = copy.deepcopy(param_dict['b1'].data)\n",
        "model.linear3.weight.data = copy.deepcopy(param_dict['W2'].data)\n",
        "model.linear3.bias.data = copy.deepcopy(param_dict['b2'].data)\n",
        "#########I had to remove all the transposes for some reason\n",
        "#Run the assert statement below to check they match\n",
        "for i,(data, _) in enumerate(train_loader):\n",
        "    data= data.to(device)\n",
        "    assert(((model(data)-my_nn(data, param_dict))**2).mean()<1e-4) # check that all the outputs are roughly equal\n",
        "print(\"All Clear !\")"
      ],
      "metadata": {
        "id": "-2j98UsXTqza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e72db0-f9e1-432b-8083-c6e5fcc9bfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Clear !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4WyZ8PFFuMT"
      },
      "source": [
        "#Exercise 4: Calculating gradients.\n",
        "\n",
        "For a single mini-batch of 256 samples (you can select any minibatch), compute the gradient of the average of the neural network outputs (over the minibatch) w.r.t to the weights.\n",
        "\n",
        "### Let's break this down:\n",
        "\n",
        "First you will need to get the mean/average of the outputs. Then you need find the gradient of this mean w.r.t to the weights.\n",
        "\n",
        "To find the gradient you can use torch autograd, which you can use simply it by calling **.backward()** on the desired variable.\n",
        "\n",
        "Your task is to print the gradients for the first layer weight and bias. You can use either the model defined from exercise 2 or 3 for this.  \n",
        "\n",
        "**Note**: The network here is $f: \\mathbf{R}^{HW}\\rightarrow\\mathbf{R}$, which means that your input layer has $HW$ neurons ($HW$ features) and your output layer has one output neuron (one scalar output = class). Since each batch has $256$ samples, the mean can be obtained by $o=\\frac{1}{256}\\sum_{i=0}^{255}f(x_i)$ or simply calling **.mean()** on the output of the network. You are asked to find $\\nabla_w o$ and $\\nabla_b o$. To access the gradient of each parameter you can call **.grad**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WoNwefYGPWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74fb8f0-60d2-4776-b9af-a604a4b3d3d3"
      },
      "source": [
        "output = model(data)\n",
        "\n",
        "\n",
        "batch = next(iter(train_loader))  # This gets the first batch\n",
        "data, target = batch\n",
        "\n",
        "data = data.to(device)\n",
        "\n",
        "\n",
        "mean_output = output.mean()\n",
        "\n",
        "######?????\n",
        "# output.backward()\n",
        "mean_output.backward()\n",
        "\n",
        "\n",
        "print(\"Gradient of W0:\", model.linear1.weight.grad)\n",
        "print(\"Gradient of b0:\", model.linear1.bias.grad)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of W0: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
            "Gradient of b0: tensor([ 6.3167e-02,  1.2765e+00, -4.0644e-01, -2.1140e-01,  6.1199e-01,\n",
            "         3.8446e-01, -1.3164e+00, -4.9131e-02,  4.2893e-01, -9.0387e-02,\n",
            "         4.9596e-01,  3.6294e-01,  3.1988e+00, -1.8296e+00, -1.4712e+00,\n",
            "        -5.1948e-02, -9.1617e-01,  1.8231e+00,  7.4958e-01, -4.3631e-01,\n",
            "        -1.0670e+00, -2.0875e-02, -4.4720e-01, -3.3320e-01, -4.5711e-01,\n",
            "         1.9940e-01, -6.7924e-01, -6.4073e-01,  4.5999e-01,  3.4104e+00,\n",
            "        -6.4379e-01,  4.0033e-01,  2.9669e-01,  1.2080e-01, -3.6049e-01,\n",
            "        -2.6728e-01, -9.9169e-01,  1.3765e-01,  2.2505e+00, -2.6776e-01,\n",
            "        -8.1288e-02, -2.5439e-01, -7.7363e-01,  9.5889e-04,  1.9166e-01,\n",
            "        -5.8205e-02, -2.8247e-01,  1.6444e+00,  8.4589e-01,  6.2192e-02,\n",
            "        -1.9467e+00, -2.6156e+00,  6.5629e-02,  0.0000e+00, -9.0796e-02,\n",
            "         1.5594e-01,  2.3544e-02,  1.3398e-02, -5.2130e-01,  1.6807e+00,\n",
            "         1.4458e+00, -4.5170e-02, -1.7696e-01, -1.9103e-01,  3.1617e-01,\n",
            "         2.2216e-02,  3.0751e-01, -4.3209e-01,  2.1127e+00, -7.5215e-01,\n",
            "        -7.4187e-01,  1.8192e-01, -6.9515e-01, -9.0821e-01, -8.5199e-02,\n",
            "        -2.6959e-02, -6.7113e-01, -1.5106e+00, -3.3455e-01, -4.2567e-02,\n",
            "         2.7568e-01,  1.9140e-02, -1.8479e+00,  9.6672e-02, -3.4954e-01,\n",
            "         5.7036e-02, -3.1791e-01, -6.4474e-02, -1.2282e+00,  1.1878e+00,\n",
            "        -4.9579e-02, -9.2538e-01,  5.2222e-01, -8.0950e-01, -2.9236e-01,\n",
            "         1.9659e+00, -1.1565e-02, -6.0552e-01,  7.7516e-04,  7.2637e-01,\n",
            "        -2.7096e-01,  1.3438e-02,  2.1366e+00, -6.9575e-01, -1.5271e-02,\n",
            "         4.2490e-01,  9.6014e-01,  1.1097e+00, -4.2410e-02, -8.6567e-02,\n",
            "        -3.0594e-01,  0.0000e+00, -3.8405e-01, -5.3598e-01, -1.3920e-03,\n",
            "        -4.7006e-01, -6.7378e-02,  2.2590e-02, -2.6558e-01, -2.5091e-01,\n",
            "        -2.2902e-01,  1.2720e-01, -1.6749e-01, -2.9107e-01, -1.6794e-01,\n",
            "        -4.9058e-01,  9.4881e-02, -2.7863e-01], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YHbWOIQHKow"
      },
      "source": [
        "#Exercise 5: CPU or GPU ?\n",
        "\n",
        "Below you will find code for comparing the speed of a model on CPU and GPU as well as comparing the speed of a forward pass to a forward/backward pass. Instantiate a version of your model from exercise 3 (preferably a larger version e.g. width 100 or 500) and run the timing code.\n",
        "\n",
        "Write 1-2 sentences to summarize your observations about the relative speed's of CPU/GPU and forward/backward"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate a model defined from (3) here\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "jIP99BLcd6mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run on CPU\n",
        "import time as timer\n",
        "data = data.to('cpu')\n",
        "model.cpu()\n",
        "\n",
        "print('Running on CPU')\n",
        "\n",
        "start = timer.time()\n",
        "for _ in range(10):\n",
        "  model(data)\n",
        "print(\"Time taken forward\", timer.time() - start)\n",
        "\n",
        "start = timer.time()\n",
        "for _ in range(10):\n",
        "  out = model(data).mean()\n",
        "  out.backward()\n",
        "print(\"Time taken forward/backward\", timer.time() - start)"
      ],
      "metadata": {
        "id": "U_YXGlTaeC_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f759f19-0234-4109-c467-f4fcb1561a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CPU\n",
            "Time taken forward 0.015603780746459961\n",
            "Time taken forward/backward 0.033127784729003906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run on GPU\n",
        "#initialize cuda\n",
        "data = data.to('cuda')\n",
        "model.cuda()\n",
        "model(data)\n",
        "print('Running on GPU')\n",
        "\n",
        "\n",
        "start = timer.time()\n",
        "for _ in range(10):\n",
        "  model(data)\n",
        "torch.cuda.synchronize()\n",
        "print(\"Time taken\", timer.time() - start)\n",
        "\n",
        "start = timer.time()\n",
        "for _ in range(10):\n",
        "  out = model(data).mean()\n",
        "  out.backward()\n",
        "torch.cuda.synchronize()\n",
        "print(\"Time taken forward/backward\", timer.time() - start)"
      ],
      "metadata": {
        "id": "KNTKRXeWePzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18ca42c-6d72-4912-84fa-3423899aba7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on GPU\n",
            "Time taken 0.002917051315307617\n",
            "Time taken forward/backward 0.009853839874267578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of observations here:"
      ],
      "metadata": {
        "id": "1oLuAwYyeqqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear that GPU is faster than CPU, however the cpu's backward pass is around two times its forward pass, but the gpu's backward pass is three times more, indicating that for cpu, backward passes are less expensive. But regardless, gpu is still faster."
      ],
      "metadata": {
        "id": "PXHrN59iJVQI"
      }
    }
  ]
}